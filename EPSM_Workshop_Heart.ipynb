{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "r-mNdbmxiP1C",
        "YUeRIK3nufjp",
        "kDuFs6i9i1Zx"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JakeKendrick1/Machine_Learning_EPSM/blob/main/EPSM_Workshop_Heart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EPSM Machine Learning Workshop\n",
        "\n",
        "Contacts:\n",
        "* Jake Kendrick: jake.kendrick@research.uwa.edu.au\n",
        "* Brani Rusanov: branimir.rusanov@research.uwa.edu.au\n",
        "\n",
        "Welcome to the first part of the EPSM Workshop. Today, we'll be taking you through a worked example of applying machine learning techniques for predictive modelling on a tabular dataset comprised of clinical variables. The structure of this session will proceed as follows: \n",
        "* Basics of Python\n",
        "* Dataset Exploration\n",
        "* Model Training and Evaluation\n",
        "\n",
        "In this first session, we will not be assuming much prior knowledge when it comes to utilising Python for training and testing Machine Learning (ML) models, so this will largely be a guided session where we keep things relatively simple. If you are already above the beginner level when it comes to ML model development, don't worry, as we progress to the later sessions we will be covering more advanced concepts. The goal is that hopefully everyone in the room, regardless of current knowledge or expertise levels, will get something out of this day. "
      ],
      "metadata": {
        "id": "XvCxdcO2tW1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python Basics\n",
        "\n",
        "Imports: 3rd party libraries can be downloaded and utilized. These packages include pre-defined functions we can call on which are useful for our particular project, so that we need not re-invent the wheel."
      ],
      "metadata": {
        "id": "gqPCxpRt3dmN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnat26mz3x8N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #tabular data manipulation package\n",
        "import numpy as np #array and number manipulation package\n",
        "import sklearn #comprehensive machine learning framework package"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic python operations (add etc)\n",
        "4 + 4"
      ],
      "metadata": {
        "id": "vqgBucNsjdbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Python, you can define custom functions to perform task specific operations. The proper way to define a basic subtraction function is as follows:"
      ],
      "metadata": {
        "id": "p3I_3uu22330"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def subtraction(x,y):\n",
        "  return x-y"
      ],
      "metadata": {
        "id": "R2-5MTHQ38vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = subtraction(5,2)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "vS6Gd0XK4DEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Python, there are a number of different data types that specify what operations we can perform on different variables. Three of the most common data types that you'll encounter in python are strings, integers, and floats. "
      ],
      "metadata": {
        "id": "oveF3ke00ERT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# String example\n",
        "string = 'This is a string'\n",
        "\n",
        "# Integer example\n",
        "integer_value = 2002\n",
        "\n",
        "# Float example \n",
        "float_value = 6.75"
      ],
      "metadata": {
        "id": "ArN-Ckl11W-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also store data in various different data containers that we can perform useful operations on. One of the most common examples of a data container is called a list, instantiated with square brackets [ ] "
      ],
      "metadata": {
        "id": "jDXwN5fv3Gdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python_list = [1,2,3]\n",
        "print(python_list)"
      ],
      "metadata": {
        "id": "XCqNaSRu4KiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then use this list and convert it into a number of other useful data containers using the packages that we imported above. \n",
        "\n",
        "* Numpy arrays allow us to perform a huge number of mathematical array operations on our data. Almost every data science project will make use of numpy in some way. \n",
        "\n",
        "* Pandas dataframes make analysis of tabular data very easy and intuitive using their library of functions. This will be the primary data container we will be using as we proceed with the machine learning analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "J5xUwXVm4OBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert our list into numpy array\n",
        "numpy_array = np.array(python_list)\n",
        "\n",
        "#Convert our list into pandas dataframe\n",
        "pandas_dataframe = pd.DataFrame(python_list)"
      ],
      "metadata": {
        "id": "kM7KOXv__JY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'This is a Numpy array: \\n{numpy_array}')\n",
        "print(f'This is a Pandas DataFrame: \\n{pandas_dataframe}')"
      ],
      "metadata": {
        "id": "FEVSHvSw5sp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is generally important to know the format in which you are storing your data, since this will effect how various operations performed on them are conducted.\n",
        "\n",
        "For example, lists cannot perform direct mathematical operations, whereas numpy arrays and pandas dataframes can. "
      ],
      "metadata": {
        "id": "qlx5OvgG8pvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Pandas dataframe elementwise addition: \\n{pandas_dataframe+3}\")\n",
        "\n",
        "print(f\"Numpy array elementwise addition: \\n{numpy_array+3}\")"
      ],
      "metadata": {
        "id": "QImfy2Vk9bCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"List elementwise addition: \\n{python_list+3}\")"
      ],
      "metadata": {
        "id": "N_FKK3aJCN_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration\n",
        "\n",
        "In this tutorial session, we will be analysing a tabular dataset consisting of a variety of different clinical variables. The goal will be to use these clinical variables to build a model that can diagnose the patient with heart disease. Let's download our dataset and have a look at it. "
      ],
      "metadata": {
        "id": "ImaSpvHf8wDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We can download GitHub repositories directly to our drive using the following command\n",
        "!git clone https://github.com/JakeKendrick1/Machine_Learning_EPSM.git"
      ],
      "metadata": {
        "id": "JB7u7k1E33fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/Machine_Learning_EPSM/heart_data_EPSM.csv' #get filepath\n",
        "data_df = pd.read_csv(data_dir) #open csv using pandas\n",
        "data_df #visualize dataframe"
      ],
      "metadata": {
        "id": "_0N5ydRv38YM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we have imported the data into a pandas dataframe. As you can see, this is essentially a 2D spreadsheet-like structure that is very useful for storing tabular data. It is capable of storing many different types of data, including floats, integers, and strings. "
      ],
      "metadata": {
        "id": "8HRSSXjU68Kz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**About the Dataset**\n",
        "\n",
        "1. age - age in years\n",
        "\n",
        "2. sex - sex (1 = male; 0 = female)\n",
        "\n",
        "3. cp - chest pain type (1 = typical angina; 2 = atypical angina; 3 = non-anginal pain; 0 = asymptomatic)\n",
        "\n",
        "4. trtbps - resting blood pressure (in mm Hg on admission to the hospital)\n",
        "\n",
        "5. chol - serum cholestoral in mg/dl\n",
        "\n",
        "6. fbs - fasting blood sugar > 120 mg/dl (1 = true; 0 = false)\n",
        "\n",
        "7. restecg - resting electrocardiographic results (1 = normal; 2 = having ST-T wave abnormality; 0 = hypertrophy)\n",
        "\n",
        "8. thalachh - maximum heart rate achieved\n",
        "\n",
        "9. exng - exercise induced angina (1 = yes; 0 = no)\n",
        "\n",
        "10. oldpeak - ST depression induced by exercise relative to rest\n",
        "\n",
        "11. slp - the slope of the peak exercise ST segment (2 = upsloping; 1 = flat; 0 = downsloping)\n",
        "\n",
        "12. caa - number of major vessels (0-3) colored by flouroscopy\n",
        "\n",
        "13. thall - 2 = normal; 1 = fixed defect; 3 = reversable defect\n",
        "\n",
        "14. output - coronary artery diameter narrowing measured on angiogram - This is what we are trying to predict (Value 0 = < 50% diameter narrowing; Value 1 = > 50% diameter narrowing). \n",
        "\n",
        "\n",
        "So, we have 13 columns corresponding to features that we can use to build our predictive model, and one column pertaining to what we are trying to predict. Our target variable is essentially a risk classification for that particular patient - a value of 1 corresponds to a patient at high risk of heart attack, and a value of 0 corresponds to a patient at lower risk of heart attack. \n",
        "\n",
        "If you want to know more about this dataset, you can see the associated paper [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4468223/)."
      ],
      "metadata": {
        "id": "0szcriWj4Trh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Quick data overview.\n",
        "data_df.info()"
      ],
      "metadata": {
        "id": "HLYiZL_k4EdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We have nans\n",
        "print(data_df.isnull().sum())"
      ],
      "metadata": {
        "id": "5cSqp0JY4cVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "id": "pfIzn3rGY1fA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When analysing real world datasets, the data that you have may be incomplete. However, most trainable machine learning models require numerical data for each instance. Before undertaking any training, we must identify any missing values and replace them in a process called **imputing**. Several techniques exist for handling missing data:\n",
        "* Removing entire instances where data is missing\n",
        "* Univariate imputation: use single feature dimension to estimate missing value. Can use mean, median, mode, constant\n",
        "* multivariate imputation: use all data to estimate missing values. Missing values are estimated using ancillary model which uses all other features to predict missing values\n",
        "\n",
        "The key thing to remember, as with almost everything in machine learning, we don't know in advance which of these methods will produce the best results. "
      ],
      "metadata": {
        "id": "QoL658ZoJ7yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's have a look and see if we are missing any target variables in our dataset.\n",
        "idx_na = np.where(data_df['output'].isna())[0]\n",
        "for i in idx_na:\n",
        "  print(f'Data instance {i} is missing a target variable.')"
      ],
      "metadata": {
        "id": "PxNfAJQS4rnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do we do with these cases where we are missing the outcome variable? Can we simply replace it with the mean or median? In this instance, imputing is not a good strategy. Since we are attempting to predict the outcome variable, and if by chance we impute the wrong value this could have a detrimental effect on our model performance. It is safer in this case, since there is only two instances for which we are missing information, to remove these patients from the dataset."
      ],
      "metadata": {
        "id": "1e95YDbgwGDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = data_df.drop(axis=0, index=idx_na)\n",
        "data_df = data_df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "k6IgboxW4wxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.info()"
      ],
      "metadata": {
        "id": "GCtTO7jY41hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, two patients have been removed from out data, but we no longer have missing values for out output"
      ],
      "metadata": {
        "id": "OVutC5K1RaOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_df)"
      ],
      "metadata": {
        "id": "R-CuObjz_GQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's separate our outcomes and predictive features in order to apply imputation methods on missing data:"
      ],
      "metadata": {
        "id": "KV95lRoiRTLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#separate output (y) from training data (x).\n",
        "feats = data_df.drop(axis=1,labels=['output'])\n",
        "diagnosis = data_df['output']"
      ],
      "metadata": {
        "id": "2ku96_9243M0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking where nan occurs for 'chol' feature\n",
        "idx_na_chol = np.where(feats['chol'].isna())[0]\n",
        "print(idx_na_chol)"
      ],
      "metadata": {
        "id": "MZpuC-jw5EHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('sanity check instance 11: '+str(feats['chol'][11]))\n",
        "print('sanity check instance 12: '+str(feats['chol'][12]))"
      ],
      "metadata": {
        "id": "3N9JOg4I5WEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Univariate data imputer: replace missing values with column mean\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer_univariate = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "df_imputed_uni = imputer_univariate.fit_transform(feats)"
      ],
      "metadata": {
        "id": "RMUg1ceQ5izF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_imputed_uni)"
      ],
      "metadata": {
        "id": "sbBVUvQyXUDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that this imputer function does not return a pandas dataframe, but instead returns a numpy array. It is important to keep track of the format in which your data is being stored. You can check this using the 'type' function. We'll need to convert this back to a pandas dataframe later."
      ],
      "metadata": {
        "id": "8RXq7vBpXlgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking to see if imputer replaced nan. \n",
        "print('sanity check instance 11: '+str(df_imputed_uni[11,4]))\n",
        "print('sanity check: imputed instance: '+str(df_imputed_uni[12,4]))"
      ],
      "metadata": {
        "id": "_rJN2MA45oyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1**\n",
        "\n",
        "1. Replace the missing data using the univariate imputer, except this time using the *median* instead of the mean. Don't forget to assign it to a new variable!\n",
        "2. Print out the imputed value using the examples above as a guide.\n",
        "* Hint: Check the SimpleImputer function [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) if you're having trouble."
      ],
      "metadata": {
        "id": "ywaePU59T90u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Median univariate imputer\n",
        "\n"
      ],
      "metadata": {
        "id": "b-SZTCKTT-rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are also other more complicated methods for imputing missing data, such as multivariate imputation. Here, missing values are predicted based on their relationship to the other variables."
      ],
      "metadata": {
        "id": "wFSHqPgrU_5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Multivariate data imputer: replace missing vlaues with estimated values\n",
        "from sklearn.experimental import enable_iterative_imputer \n",
        "from sklearn.impute import IterativeImputer\n",
        "imputer_multivariate = IterativeImputer(missing_values=np.nan, initial_strategy='mean')\n",
        "df_imputed_multi = imputer_multivariate.fit_transform(feats)"
      ],
      "metadata": {
        "id": "iL82zQsI542u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking to see if imputer replaced nan\n",
        "print('sanity check instance 11: '+str(df_imputed_multi[11,4]))\n",
        "print('sanity check imputed instance: '+str(df_imputed_multi[12,4]))"
      ],
      "metadata": {
        "id": "Ao27BsUh6BJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In summary, there are a myriad of different ways in which you can deal with missing data, each resulting in a different imputed data value. \n",
        "\n",
        "Next, we convert our imputed variables, which are stored in a numpy array, back into a pandas dataframe:"
      ],
      "metadata": {
        "id": "p5h6xtaSZkxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting cleaned features back into dataframe for feature selection\n",
        "feats_cleaned = pd.DataFrame(df_imputed_multi,columns=list(feats))\n",
        "feats_cleaned"
      ],
      "metadata": {
        "id": "cl2gJQr76GAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(feats_cleaned.isnull().sum())"
      ],
      "metadata": {
        "id": "UgpELgtSaFLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After our quick data cleaning process, we now have no more missing values in our dataset. We've removed the rows where there is no target variable, and have replaced missing values in the feature columns using a multivariate imputing method."
      ],
      "metadata": {
        "id": "k7CHh8A4aY39"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Pandas, it is trivially easy to calculate summary statistics on each of the columns in our tabular dataset. "
      ],
      "metadata": {
        "id": "Vy-85KUpomVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Summarise feature statistics:\n",
        "feats_cleaned.describe().transpose()"
      ],
      "metadata": {
        "id": "ETsCs5kU9EiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Types of Features**\n",
        "\n",
        "* As we can see from our tabulated summary statistics, some of our features are *continuous variables*, and some are *categorical variables*. \n",
        "* If our categorical variables are not *ordinal* (ordered by severity), our model will interpret higher values as higher real-world values. \n",
        "* The 'sex' feature is a perfect example of this, where a higher value (1 = Male) does not correspond to a higher real-world value. \n",
        "* The model will interpret this as the 1 value having greater significance than the 0 value, even though this is untrue."
      ],
      "metadata": {
        "id": "IFUsMNFLpphZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can counter this by [one-hot encoding](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/) all of our categorical variables. This process creates a new binary feature for each possible value of the categorical variable, and assigns a 1 to the new feature that corresponds with the old category for each data point. 'Sex' will therefore be split into two new features, one for males and one for females.\n",
        "* One-hot-encoding could also be used if the Sex column contained text, i.e. 'Male' for males and 'Female' for females."
      ],
      "metadata": {
        "id": "xlNqS7h3sCUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lists of categorical and continuous variables\n",
        "cat_cols = ['sex','exng','caa','cp','fbs','restecg','slp','thall']\n",
        "con_cols = [\"age\",\"trtbps\",\"chol\",\"thalachh\",\"oldpeak\"]"
      ],
      "metadata": {
        "id": "wallYwvR9i1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#One-hot encoding the categorical variables using in built pandas function\n",
        "feats_cleaned = pd.get_dummies(feats_cleaned, columns = cat_cols, drop_first = False)"
      ],
      "metadata": {
        "id": "AER_ybs59x71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feats_cleaned.describe().transpose()"
      ],
      "metadata": {
        "id": "gjDo6ruk-ecU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection\n",
        "\n",
        "It is very common when training ML models to undergo a process of feature selection. There are a few reasons we might want to not use all the features in our dataset:\n",
        "\n",
        "1. Redundancy: Features that are highly correlated with each other are unlikely to provide useful additional information to the model\n",
        "2. Non-descriptive: Some features won't have a good relationship with the target variable.\n",
        "3. Dimensionality Reduction: The more features you have in your predictive model, the higher the chance of overfitting. \n",
        "\n",
        "\n",
        "Lets first visualise the correlation between features using a handy function to display the diagonal correlation matrix:"
      ],
      "metadata": {
        "id": "YRbrd_g2siqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the correlation between all of our features\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "corrMatrix = feats_cleaned.corr() #computes Pearson Correlation coefficients\n",
        "plt.figure(figsize=(25,25))\n",
        "sn.heatmap(corrMatrix, annot=True, cmap = 'bwr')"
      ],
      "metadata": {
        "id": "LIqN8g3AxqgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We note that most features are uncorrelated (~0), with most correlated features being one-hot-encoded variables of the original feature, suggesting there are minimal redundant features in our data"
      ],
      "metadata": {
        "id": "WDS9lReLW-ln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Selection: ANOVA-F Value**\n",
        "\n",
        "There are many ways in which features can be selected. One method is to compare the mean and variance of each of our features for the two possible target variable outcomes. If a feature has a similar mean and variance for both target outcomes, then it is unlikely to discriminate between the two very well. We can rank features based on this criteria using the ANOVA f-value, and choose the top 'k' features we want to use. "
      ],
      "metadata": {
        "id": "rdwnfoYGWP5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature selection based on ANOVA f-value\n",
        "\n",
        "NUM_FEATURES_CHOSEN = 5 #Modify the top number of features to use.\n",
        "\n",
        "from sklearn.feature_selection import GenericUnivariateSelect, f_classif\n",
        "transformer = GenericUnivariateSelect(f_classif, mode='k_best', param = NUM_FEATURES_CHOSEN)\n",
        "feats_cleaned_reduced = transformer.fit(feats_cleaned, diagnosis)"
      ],
      "metadata": {
        "id": "Ioy53ovp6Xyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying Selected Features\n",
        "features_selected = feats_cleaned_reduced.get_support(indices = True)\n",
        "feat_names = []\n",
        "for feature_index in features_selected:\n",
        "    feat_names.append(list(feats_cleaned)[feature_index])\n",
        "\n",
        "print(feat_names)"
      ],
      "metadata": {
        "id": "7zUXs9lvqQXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transforming our data into just the selected features\n",
        "feats_cleaned_reduced = transformer.fit_transform(feats_cleaned, diagnosis)"
      ],
      "metadata": {
        "id": "Yuxfn2Eoq5c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is one of the ways in which the feature space can be reduced. As always, experimentation with many different types is advisable. A general rule of thumb is that you should have at least **10 training samples for every feature in your predictive model** to minimise the chances of overfitting."
      ],
      "metadata": {
        "id": "QYv6xPqU6yuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking is data is balanced:\n",
        "diagnosis.value_counts()"
      ],
      "metadata": {
        "id": "PSu8YvqvM08w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the class ratios of our target variable is important, as it can affect drastically how we interpret the results of the model. \n",
        "\n",
        "Splitting our data in preparation for training. We use a 80:20 training-to-testing set split"
      ],
      "metadata": {
        "id": "bOcNukaTXP8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split our data into training and testing sets\n",
        "\n",
        "TEST_SIZE = 0.20\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(feats_cleaned_reduced, diagnosis, test_size = TEST_SIZE, random_state=10)\n",
        "print('train features: '+str(X_train.shape))\n",
        "print('train targets: '+str(y_train.shape))\n",
        "print('test features: '+str(X_test.shape))\n",
        "print('test targets: '+str(y_test.shape))\n",
        "y_train = list(y_train)\n",
        "y_test = list(y_test)"
      ],
      "metadata": {
        "id": "wt0HlEcV6q5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Normalisation"
      ],
      "metadata": {
        "id": "fBaeH03QYWDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalising feature values before training ML models is important, as it reduces model bias towards large absolute features and generally improves model stability. First, we will normalise our data to be between a range of 0 and 1. We do this using only the training data, and then use the statistics calculated for the training data on the testing set, to prevent data leakage. We assume that the data distribution of the training set approximates that which it will be tested and used on in the real world. "
      ],
      "metadata": {
        "id": "AjL7mwwAa3c8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MinMax Scaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler_minmax = MinMaxScaler()\n",
        "scaler_minmax.fit(X_train)\n",
        "X_train_scaled_minmax = scaler_minmax.transform(X_train)\n",
        "X_test_scaled_minmax = scaler_minmax.transform(X_test) #using statistics of training data to scale testing data"
      ],
      "metadata": {
        "id": "-BTdTV1KuXpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2**\n",
        "\n",
        "1. Import the sklearn StandardScaler (hint: see the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)!)\n",
        "2. Standardise the training and testing data using this StandardScaler, with the help of the example above. The variable names have been provided to you below."
      ],
      "metadata": {
        "id": "tvoncmTHvJT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X_train_scaled = \n",
        "X_test_scaled = "
      ],
      "metadata": {
        "id": "cladbicg7oqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training and Evaluation"
      ],
      "metadata": {
        "id": "LvuYOPLInpLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having created a standardised set of features with associated outputs, we are now ready to begin training some ML models. We will implement a few different types of models that you have heard about in the opening presentation, and then evaluate them using some standard classification metrics.\n",
        "\n",
        "Below we have implemented some convenient functions that we can re-use as we are trying out different models in this process. They will also help you in your final task!"
      ],
      "metadata": {
        "id": "JdxRioAwclfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing models and testing metrics\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve\n",
        "from yellowbrick.classifier import ROCAUC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "#Function to rapidly train and evaluate trained models.\n",
        "def train_model(model, train_x, train_y, test_x, test_y):\n",
        "  model.fit(train_x, train_y)\n",
        "  model_pred_training = model.predict(train_x)\n",
        "  model_pred_testing = model.predict(test_x)\n",
        "  model_pred_testing_proba = model.predict_proba(test_x)[:, 1]\n",
        "  model_acc_train = accuracy_score(model_pred_training, train_y)\n",
        "  model_acc_test = accuracy_score(model_pred_testing, test_y)\n",
        "  model_auc = roc_auc_score(test_y, model_pred_testing_proba)\n",
        "  return model_acc_train, model_acc_test, model_auc, model_pred_testing_proba, model_pred_testing\n",
        "\n",
        "def roc_auc_curve (predicted_probabilities, y_test, title = str):\n",
        "  \n",
        "  '''\n",
        "  Function will plot the receiver operater charactistic curve for a given\n",
        "  set of model predictions.\n",
        "\n",
        "  Inputs:\n",
        "      predicted_probabilities (array): Model predicted probabilities\n",
        "      y_test (array): Ground truth classifications.\n",
        "      title (str): Title of the plot\n",
        "  '''\n",
        "\n",
        "  fpr, tpr, _ = roc_curve(y_test,  predicted_probabilities)\n",
        "  plt.figure()\n",
        "  lw = 2\n",
        "  plt.step(\n",
        "    fpr,\n",
        "    tpr,\n",
        "    color=\"darkorange\",\n",
        "    lw=lw,\n",
        "    label=\"ROC curve (area = %0.3f)\" % auc,\n",
        "  )\n",
        "  plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
        "  plt.xlim([-0.01, 1.0])\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlabel(\"False Positive Rate\")\n",
        "  plt.ylabel(\"True Positive Rate\")\n",
        "  plt.title(title)\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "_vezGsSZngXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROC Curves**"
      ],
      "metadata": {
        "id": "1FmNbkg6C9x1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Receiver Operating Characteristic (ROC) curve is a very common and robust metric that tests the discriminatory power of our model at various thresholds. That is, it tests the ability of our model to discriminate between the presence and absence of the target that we are trying to predict. It is a substantially better metric than accuracy for the following reasons:\n",
        "* It is more robust to class imbalances.\n",
        "* It gives us information on how the model predicts the positive and negative classes. This could be of substantial clinical value.\n",
        "* Accuracy is calculated at only one threshold (defaults to 0.5), ROC curves are threshold invariant."
      ],
      "metadata": {
        "id": "SvTt1908CmHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**\n",
        "\n"
      ],
      "metadata": {
        "id": "-w68-QRseUoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n",
        "acc_train, acc_test, auc, prediction_proba, predictions = train_model(model, X_train_scaled, y_train, X_test_scaled, y_test)\n",
        "print(f'Training Accuracy: {acc_train:.3f}, Testing Accuracy: {acc_test:.3f}')\n",
        "print(f'Testing AUC Value: {auc:.3f}')"
      ],
      "metadata": {
        "id": "uqiU1EZ5eUGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AUC Plot\n",
        "roc_auc_curve(prediction_proba, y_test, 'Logistic Regression ROC')"
      ],
      "metadata": {
        "id": "UImSPp2jdzKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also display a confusion matrix to assess which for classes the model makes incorrect predictions. The most clinically significant case is the false negative case, where the model predicts a low risk when in fact the patient of high risk (bottom left quadrant)  "
      ],
      "metadata": {
        "id": "46GUhKpdasV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = ['Low Risk', 'High Risk'])\n",
        "disp.plot()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y5hpSAkLiQ8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Support Vector Machine**"
      ],
      "metadata": {
        "id": "47m-4Wlzc2SM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = svm.SVC(kernel='linear', probability=True)\n",
        "acc_train, acc_test, auc, prediction_proba, predictions = train_model(model, \n",
        "                                                                      X_train_scaled, y_train, X_test_scaled, y_test)\n",
        "print(f'Training Accuracy: {acc_train:.3f}, Testing Accuracy: {acc_test:.3f}')\n",
        "print(f'Testing AUC Value: {auc:.3f}')"
      ],
      "metadata": {
        "id": "RjhyEGZZpcKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AUC Curve\n",
        "roc_auc_curve(prediction_proba, y_test, 'SVM ROC')"
      ],
      "metadata": {
        "id": "G4MhpGaxeora"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = ['Low Risk', 'High Risk'])\n",
        "disp.plot()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TtgTpj_Hkcug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3**\n",
        " \n",
        "1. Train a Decision Tree model on our data. Check the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). \n",
        "2. Plot the ROC curve for this model on the testing data.\n",
        "3. If you have time, try changing some of the hyperparameters of the model!\n",
        "\n",
        "Use the helper functions and examples above to guide you through this."
      ],
      "metadata": {
        "id": "V_DYN-kMgC2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision tree model\n",
        "\n"
      ],
      "metadata": {
        "id": "Ge9IVkrpjSuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Boosting Classifier**\n",
        "\n",
        "As you may have seen above, some ML models have multiple different hyperparameters that you can specify. Almost always, the default parameters will not yield the best model. Thus, we can specify a multitude of them and search the hyperparameter space for the best combination. "
      ],
      "metadata": {
        "id": "9ZoaEfjEd8dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#implementing grid search for XGboost model:\n",
        "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
        "#defining hyperparameter grid search parameters\n",
        "loss = ['deviance', 'exponential']\n",
        "max_depth = [i for i in range(1, 50, 10)]\n",
        "min_impurity_decrease = [i for i in range(0,50, 10)]\n",
        "min_samples_leaf = [i for i in range(1,50,10)]\n",
        "\n",
        "list_loss = []\n",
        "list_max_depth = []\n",
        "list_min_impurity_decrease = []\n",
        "list_min_samples_leaf = []\n",
        "list_test_acc = []\n",
        "list_auc = []\n",
        "list_preds = []\n",
        "\n",
        "for i in loss:\n",
        "  for j in max_depth:\n",
        "    for k in min_impurity_decrease:\n",
        "      for z in min_samples_leaf:\n",
        "        model_xgb = GBC(loss = i, max_depth = j, min_impurity_decrease = k, min_samples_leaf = z, random_state=20) #describe random state\n",
        "        acc_train, acc_test, auc, predictions_proba, predictions = train_model(model_xgb, X_train_scaled, y_train, X_test_scaled, y_test)\n",
        "        list_loss.append(i)\n",
        "        list_max_depth.append(j)\n",
        "        list_min_impurity_decrease.append(k)\n",
        "        list_min_samples_leaf.append(z)\n",
        "        list_test_acc.append(acc_test)\n",
        "        list_auc.append(auc)\n",
        "        list_preds.append(predictions)\n",
        "\n"
      ],
      "metadata": {
        "id": "mRr_hZQGtpba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Best AUC value achieved during the hyperparameter search = {np.max(list_auc):.3f}')"
      ],
      "metadata": {
        "id": "AM9q3X2W0Tnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting the index of the best model from our list of saved metrics.\n",
        "index = np.where(list_auc==np.max(list_auc))[0][0]\n",
        "\n",
        "print(f'Hyperparameter set {index} had the best AUC')"
      ],
      "metadata": {
        "id": "tZhyElSM7KKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting best hyperparameters of best model\n",
        "print(f'Best hyperparameters: \\n Loss = {list_loss[index]}\\n Max Depth = {list_max_depth[index]}')\n",
        "print(f' Min Impurity Decrease = {list_min_impurity_decrease[index]}\\n Min Samples Leaf = {list_min_samples_leaf[index]}')   "
      ],
      "metadata": {
        "id": "IheRsKU08g9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In cases where there are many hyperparameters to choose from, it is often useful to search a number of them to see if they generate a better model. In almost all cases, it will be impossible to know which ones in advance will prove to be the best! This example showed one way that you can do this, through a series of for loops."
      ],
      "metadata": {
        "id": "r98mLvnIHesu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "In this workshop, we have learned about:\n",
        "1. Type and function of common Python data containers.\n",
        "\n",
        "2. How to import tabular data into python and examine its characteristics.\n",
        "3. How to apply univariate and multivariate data Imputation techniques to fill missing values.\n",
        "4. How and why to apply one-hot-encoding for categorical features.\n",
        "5. Feature selection: creating and interpreting a correlation matrix; applying ANOVA-F feature selection method.\n",
        "6. Data normalization techniques: MinMax and Standardisation.\n",
        "7. Training models: Logistic regression, Support-Vector-Machine, Decision Tree, XGBoost.\n",
        "8. Calculation and importance of AUC, ROC curves, confusion matrices, and pitfalls of accuracy as a performance metric. \n",
        "9. How and why to perform grid search over hyperparameter space. \n",
        "\n",
        "If you have any questions or would like to get in touch with the workshop hosts, please email:\n",
        "\n",
        " jake.kendrick@research.uwa.edu.au and branimir.rusanov@research.uwa.edu.au"
      ],
      "metadata": {
        "id": "iuYS2luSdrU2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task Solutions"
      ],
      "metadata": {
        "id": "ZEdE9krViGv4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1"
      ],
      "metadata": {
        "id": "r-mNdbmxiP1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imputer_univariate_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
        "df_imputed_uni_median = imputer_univariate_median.fit_transform(feats)\n",
        "\n",
        "#Checking one of the replaced values\n",
        "print('sanity check instance 11: '+str(df_imputed_uni_median[11,4]))\n",
        "print('sanity check: imputed instance: '+str(df_imputed_uni_median[12,4]))"
      ],
      "metadata": {
        "id": "H_RsLdX14g9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2"
      ],
      "metadata": {
        "id": "YUeRIK3nufjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Standardising our training and testing data. \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "bCYiuom6ugz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3"
      ],
      "metadata": {
        "id": "kDuFs6i9i1Zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "acc_train, acc_test, auc, prediction_proba, predictions = train_model(model, \n",
        "                                                                      X_train_scaled, y_train, X_test_scaled, y_test)\n",
        "print(f'Training Accuracy: {acc_train:.3f}, Testing Accuracy: {acc_test:.3f}')\n",
        "print(f'Testing AUC Value: {auc:.3f}')"
      ],
      "metadata": {
        "id": "AQ2YbRWKxnYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AUC Curve\n",
        "roc_auc_curve(prediction_proba, y_test, 'Decision Tree ROC')"
      ],
      "metadata": {
        "id": "vJIZ2LeOi3iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, predictions)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = ['Low Risk', 'High Risk'])\n",
        "disp.plot()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f1Fq2kGyi9vu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}